{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re\n",
    "import yt_dlp\n",
    "import json\n",
    "import time\n",
    "import math \n",
    "import httplib2\n",
    "import requests\n",
    "import pinecone \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "from youtubesearchpython import *\n",
    "from langchain.llms import OpenAIChat\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import VectorDBQAWithSourcesChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lext GPT\n",
    "\n",
    "`Here, we will prepare the VectorDB index for Lex Fridman podcast:`\n",
    "\n",
    "* Scrape source data from: https://karpathy.ai/lexicap/\n",
    "* Use Whisper to transcribe episodes that Karpathy has not already done\n",
    "* Chunk data\n",
    "* Embed it to Pinecone\n",
    "* Test VectorDBQA chain on it \n",
    "* App (https://lex-gpt.vercel.app/) will read from same Pinecone DB\n",
    " \n",
    "`1. Get video urls -` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videos\n",
    "channel_id = \"UCSHZKyawb77ixDdsGog4iWA\" # Get ID from ChannelsSearch\n",
    "playlist = Playlist(playlist_from_channel_id(channel_id))\n",
    "\n",
    "# Episode data\n",
    "stor_metadata=pd.DataFrame()\n",
    "for v in playlist.videos:\n",
    "    try:\n",
    "        ep_number = int(v['title'].split(\"|\")[-1].split(\"#\")[-1])\n",
    "        stor_metadata.loc[v['title'],'number']=ep_number\n",
    "        stor_metadata.loc[v['title'],'link']=v['link']\n",
    "        stor_metadata.loc[v['title'],'title']=v['title']\n",
    "        stor_metadata.loc[v['title'],'img']=v['thumbnails'][3]['url']\n",
    "    except:\n",
    "        print(\"Failed on %s\", v['title'])\n",
    "\n",
    "last_complete_video = 365\n",
    "new_ep = stor_metadata[stor_metadata.number > last_complete_video]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. Get audio -` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through episodes \n",
    "for ix in new_ep.index:\n",
    "    \n",
    "    ep_number=int(new_ep.loc[ix,'number'])\n",
    "    print(\"EPISODE: %s\"%ep_number)\n",
    "    img_url=new_ep.loc[ix,'img']\n",
    "    ep_link=new_ep.loc[ix,'link']\n",
    "    # Write img \n",
    "    with open(\"../public/0%s.jpg\"%str(ep_number), 'wb') as f:\n",
    "        response = requests.get(img_url)\n",
    "        f.write(response.content)\n",
    "    # Write audio\n",
    "    ydl_opts = {\n",
    "    'format': 'm4a/bestaudio/best',\n",
    "    'outtmpl': 'audio/%s.m4a'%str(ep_number),\n",
    "    'noplaylist': True,\n",
    "    'postprocessors': [{  \n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'm4a',\n",
    "    }]}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        error_code = ydl.download(ep_link)\n",
    "        \n",
    "new_ep.reset_index().to_csv(\"audio_transcription/episodes.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. Run Whisper -`\n",
    " \n",
    "* On GPU, ideally: 10-20 min / video on 2080Ti with `medium` model\n",
    "* Run `python run_whisper.py`\n",
    "\n",
    "If running this step on a remote machine:\n",
    "* scp the transcription: `audio_transcription/episodes.csv`\n",
    "* scp the audio files: `audio/*`\n",
    "* Run `python run_whisper.py`\n",
    "* Then, scp the `audio_transcription/` back to local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_whisper.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4. Scrape Karpathy transcriptions -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text -\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(string=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def get_text_and_title(url):\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    t=(text_from_html(html))\n",
    "    title=t.split(\"|\")[0].split(\"back to index\")[1].strip()\n",
    "    return t, title\n",
    "\n",
    "# Get links -\n",
    "def get_links(URL):\n",
    "    http = httplib2.Http()\n",
    "    status, response = http.request(URL)\n",
    "    links = []\n",
    "    for link in BeautifulSoup(response, 'html.parser', parse_only=SoupStrainer('a')):\n",
    "        if link.has_attr('href'):\n",
    "            links.append(link['href'])\n",
    "    links_clean = [l for l in links if \"https\" in l]\n",
    "    return links_clean\n",
    "\n",
    "# Get image -\n",
    "def get_img(URL,title,episode_id):\n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    img_tags = soup.find_all('img')\n",
    "    urls = [img['src'] for img in img_tags]\n",
    "    for url in urls:\n",
    "        response = requests.get(url)\n",
    "        imgpath=\"../public/0%s.jpg\"%episode_id\n",
    "        with open(imgpath, 'wb') as f:\n",
    "            if 'http' not in url:\n",
    "                url = '{}{}'.format(site, url)\n",
    "            response = requests.get(url)\n",
    "            f.write(response.content)\n",
    "    return imgpath\n",
    "\n",
    "# Full pipeline - \n",
    "def pre_process(URL,episode_id):\n",
    "\n",
    "    t,title=get_text_and_title(URL)\n",
    "    links=get_links(URL)\n",
    "    img=get_img(URL,title,episode_id)\n",
    "    stor_chunk = pd.DataFrame()\n",
    "    stor_chunk['chunks']= t.split(\"link |\")\n",
    "    stor_chunk['clean_chunks']=stor_chunk['chunks'].apply(lambda x: re.sub(r\"[^a-zA-Z ]+\", '', x)).apply(lambda x: x.strip())\n",
    "    stor_chunk['links']=links\n",
    "    all_text = stor_chunk['clean_chunks'].str.cat(sep=' ')\n",
    "    return all_text, links, title\n",
    "\n",
    "# Make splits - \n",
    "def make_splits(chunks,URL):\n",
    "\n",
    "    # ID\n",
    "    episode_id=URL.split(\"/\")[-1].split(\"-\")[0]\n",
    "\n",
    "    # Pre-processing\n",
    "    texts,links,title=pre_process(URL,episode_id)\n",
    "    \n",
    "    # Splits \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunks, \n",
    "                                                   chunk_overlap=50) \n",
    "    texts_recusive = text_splitter.split_text(texts)\n",
    "    print(len(texts_recusive)) \n",
    "\n",
    "    # Metadata \n",
    "    N = len(texts_recusive) \n",
    "    bins = np.linspace(0, len(links)-1, N, dtype=int)\n",
    "    sampled_links = [links[i] for i in bins]\n",
    "    # Here we can add \"link\", \"title\", etc that can be fetched in the app \n",
    "    metadatas=[{\"source\":title + \" \" +link,\"id\":episode_id,\"link\":link,\"title\":title} for link in sampled_links]\n",
    "    print(len(metadatas))\n",
    "    return texts_recusive,metadatas,title,episode_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all pages \n",
    "http = httplib2.Http()\n",
    "status, response = http.request(\"https://karpathy.ai/lexicap/\")\n",
    "links = []\n",
    "for link in BeautifulSoup(response, 'html.parser', parse_only=SoupStrainer('a')):\n",
    "    if link.has_attr('href'):\n",
    "        links.append(link['href'])\n",
    "links_tx = [\"https://karpathy.ai/lexicap/\"+l for l in links if \"0\" in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Chunk size: key parameter *** \n",
    "chunks = 1500\n",
    "splits_scrape = [ ]\n",
    "metadatas_scrape = [ ]\n",
    " \n",
    "# Iterate \n",
    "stor=pd.DataFrame()\n",
    "for page in links_tx:\n",
    "    try:\n",
    "        print(\"Writing: %s\"%page)\n",
    "        # Make splits\n",
    "        splits,metadatas,title,episode_id=make_splits(chunks,page)\n",
    "        stor.loc[episode_id,'title']=title \n",
    "        with open('docs/%s.txt'%episode_id, \"w\") as f:\n",
    "            for string in splits:\n",
    "                f.write(string + \"\\n\") \n",
    "        f.close()\n",
    "        with open('metadatas/%s.json'%episode_id, \"w\") as f:\n",
    "            json.dump(metadatas, f)\n",
    "        f.close()\n",
    "        splits_scrape.append(splits)\n",
    "        metadatas_scrape.append(metadatas)\n",
    "    except:\n",
    "        print(\"Error on page: %s\"%page)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5. Get newer transcripts -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Chunk size: key parameter *** \n",
    "chunks = 1500\n",
    "splits_new = [ ]\n",
    "metadatas_new = [ ]\n",
    "\n",
    "# Read the csv file\n",
    "new_ep=pd.read_csv(\"audio_transcription/episodes.csv\",index_col=None)\n",
    "\n",
    "for ix in new_ep.index:\n",
    "\n",
    "    # Get data\n",
    "    title=new_ep.loc[ix,'title']\n",
    "    ep_number=int(new_ep.loc[ix,'number'])\n",
    "    \n",
    "    # Consistency w/ convention used in Karpathy transcription\n",
    "    episode_id=\"0\"+str(ep_number) \n",
    "    file_path='audio_transcription/%s.txt'%str(episode_id)\n",
    "    transcript=pd.read_csv(file_path,sep='\\t',header=None)\n",
    "    transcript.columns=['links','time','chunks']\n",
    "    \n",
    "    # Clean text chunks \n",
    "    transcript['clean_chunks']=transcript['chunks'].astype(str).apply(lambda x: x.strip())\n",
    "    links = list(transcript['links'])\n",
    "    texts = transcript['clean_chunks'].str.cat(sep=' ')\n",
    "\n",
    "    # Splits \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunks, \n",
    "                                                   chunk_overlap=50) \n",
    "    splits = text_splitter.split_text(texts)\n",
    "    print(len(splits)) \n",
    "\n",
    "    # Metadata \n",
    "    N = len(splits) \n",
    "    bins = np.linspace(0, len(links)-1, N, dtype=int)\n",
    "    sampled_links = [links[i] for i in bins]\n",
    "    \n",
    "    # Here we can add \"link\", \"title\", etc that can be fetched in the app \n",
    "    metadatas=[{\"source\":title + \" \" +link,\"id\":episode_id,\"link\":link,\"title\":title} for link in sampled_links]\n",
    "    print(len(metadatas)) \n",
    "\n",
    "    # Append to output \n",
    "    splits_new.append(splits)\n",
    "    metadatas_new.append(metadatas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6. Assemble final list -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the list of lists \n",
    "splits_all = []\n",
    "# For the initial write \n",
    "# for sublist in [splits_scrape+splits_new]:\n",
    "# For updates -- \n",
    "for sublist in splits_new:\n",
    "    splits_all.extend(sublist)\n",
    "\n",
    "metadatas_all = []\n",
    "# For the initial write \n",
    "# for sublist in [metadatas_scrape+metadatas_new]:\n",
    "# For updates -- \n",
    "for sublist in metadatas_new:\n",
    "    metadatas_all.extend(sublist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7. Embed full dataset in Pinecone VectorDB -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-east1-gcp\"  \n",
    ")\n",
    "\n",
    "# Initialize with small set of data - \n",
    "# p = Pinecone.from_texts(splits_all[0:2], \n",
    "#                        embeddings, \n",
    "#                        index_name=index_name, \n",
    "#                        metadatas=metadatas_all[0:2])\n",
    "\n",
    "# Update - \n",
    "index_name = \"lex-gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "p = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data in chunk to avoid data ingest errors\n",
    "chunk_size = 100\n",
    "last_chunk = 0\n",
    "num_chunks = math.ceil(len(splits_all) / chunk_size)\n",
    "for i in range(last_chunk,num_chunks):\n",
    "    \n",
    "    print(i)\n",
    "    start_time = time.time()\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min(start_idx + chunk_size, len(splits_all))\n",
    "    \n",
    "    # Extract the current chunk\n",
    "    current_splits = splits_all[start_idx:end_idx]\n",
    "    current_metadatas = metadatas_all[start_idx:end_idx]\n",
    "    \n",
    "    # Add the current chunk to the vector database\n",
    "    p.add_texts(texts = current_splits, metadatas=current_metadatas)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`8. Read in VectorDB for testing` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-east1-gcp\"  \n",
    ")\n",
    "index_name = \"lex-gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "p = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`9. Run VectorDBQAWithSourcesChain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vectordb_sources_chain(llm,query,docstore):\n",
    "\n",
    "    start_time = time.time()\n",
    "    chain = VectorDBQAWithSourcesChain.from_chain_type(llm, chain_type=\"stuff\", vectorstore=docstore)\n",
    "    a = chain({\"question\": query},return_only_outputs=True)\n",
    "    print(a[\"answer\"])\n",
    "    print(a[\"sources\"])\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"--------\")\n",
    "\n",
    "llm = OpenAIChat(temperature=0)\n",
    "q = \"What does Sam Altman think about GPT-4?\"\n",
    "run_vectordb_sources_chain(llm,q,p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
